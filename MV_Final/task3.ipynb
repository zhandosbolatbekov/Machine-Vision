{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2//Arms//\n",
      "Full dataset tensor: (784, 28, 28)\n",
      "Mean: 0.112809\n",
      "Standard deviation: 0.143145\n",
      "data2//Figure_normal_legs//\n",
      "Full dataset tensor: (619, 28, 28)\n",
      "Mean: 0.0883419\n",
      "Standard deviation: 0.163265\n",
      "data2//FigureWheels//\n",
      "Full dataset tensor: (222, 28, 28)\n",
      "Mean: 0.075104\n",
      "Standard deviation: 0.165659\n",
      "data2//Head//\n",
      "Full dataset tensor: (473, 28, 28)\n",
      "Mean: 0.0372736\n",
      "Standard deviation: 0.201234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "folders = [ \n",
    "    r'data2//Arms//',\n",
    "    r'data2//Figure_normal_legs//',\n",
    "    r'data2//FigureWheels//',\n",
    "    r'data2//Head//'\n",
    "] \n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label.\"\"\"\n",
    "    image_files = os.listdir(folder)\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "    print(folder)\n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder, image)\n",
    "        if not image.startswith('.') and image != 'Thumbs.db':\n",
    "            img = Image.open(image_file)\n",
    "            new = img.resize((28, 28), Image.ANTIALIAS)\n",
    "            try:\n",
    "                image_data = (np.array(new).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "                if image_data.shape != (image_size, image_size):\n",
    "                    raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "                dataset[num_images, :, :] = image_data\n",
    "                num_images = num_images + 1\n",
    "            except IOError as e:\n",
    "                print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "X_datasets = list()\n",
    "Y_datasets = list()\n",
    "for idx in range(len(folders)):\n",
    "    folder = folders[idx] \n",
    "    X_datasets.append(load_letter(folder, 200))\n",
    "    labels = np.zeros((X_datasets[-1].shape[0],len(folders)))\n",
    "    labels[:,idx] = 1\n",
    "    Y_datasets.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples number: (2098, 28, 28)\n",
      "Samples for tests: 525\n",
      "Samples for trains: 1573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1137b0748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X_datasets2 = np.concatenate(X_datasets)\n",
    "Y_datasets2 = np.concatenate(Y_datasets)\n",
    "print(\"Total samples number:\",X_datasets2.shape)\n",
    "X_trains,X_tests,Y_trains,Y_tests = train_test_split(X_datasets2,Y_datasets2,test_size=0.25)\n",
    "print(\"Samples for tests:\",Y_tests.shape[0])\n",
    "print(\"Samples for trains:\",Y_trains.shape[0])\n",
    "plt.imshow(X_tests[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 196)               77028     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 49)                4851      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 200       \n",
      "_________________________________________________________________\n",
      "sigmoid (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,024,545\n",
      "Trainable params: 1,024,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(784, input_shape=(784,), activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(392, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(196, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(98, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(49, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, name=\"output\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1179 samples, validate on 394 samples\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.37295, saving model to ./weights.net\n",
      " - 3s - loss: 0.4842 - acc: 0.7708 - val_loss: 0.3730 - val_acc: 0.8185\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.37295 to 0.30108, saving model to ./weights.net\n",
      " - 2s - loss: 0.2958 - acc: 0.8764 - val_loss: 0.3011 - val_acc: 0.8820\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 2s - loss: 0.2171 - acc: 0.9033 - val_loss: 0.3216 - val_acc: 0.8896\n",
      "Epoch 00003: early stopping\n",
      "525/525 [==============================] - 0s 187us/step\n",
      "[0.25558462750344052, 0.89428571439924698]\n"
     ]
    }
   ],
   "source": [
    "# Create first network with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Reshape\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import numpy\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, verbose=1),\n",
    "    # EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "    ModelCheckpoint(filepath='./weights.net', verbose=1, save_best_only=True),\n",
    "    \n",
    "]\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "input_dim = X_trains[0].shape[0]*X_trains[0].shape[1]\n",
    "print((X_trains[0].shape[0],X_trains[0].shape[1]))\n",
    "print(Y_trains[0].shape[0])\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Reshape((input_dim,), input_shape=(X_trains[0].shape[0],X_trains[0].shape[1])))\n",
    "model.add(Dense(input_dim, input_shape = (input_dim,), init='uniform', activation='relu'))\n",
    "model.add(Dense(int(input_dim/2), init='uniform', activation='relu'))\n",
    "model.add(Dense(int(input_dim/4), init='uniform', activation='relu'))\n",
    "model.add(Dense(int(input_dim/8), init='uniform', activation='relu'))\n",
    "model.add(Dense(int(input_dim/16), init='uniform', activation='relu'))\n",
    "model.add(Dense(Y_trains[0].shape[0],init='uniform', name=\"output\"))\n",
    "model.add(Activation('sigmoid', name=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_trains, \n",
    "          Y_trains, \n",
    "          epochs=50, \n",
    "          batch_size=10, \n",
    "          verbose=2, \n",
    "          validation_split=0.25,\n",
    "          callbacks=callbacks)\n",
    "# calculate predictions\n",
    "results = model.evaluate(X_tests, Y_tests, batch_size=32, verbose=1, sample_weight=None)\n",
    "# round predictions\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clazzez = ['Arms','Figure_normal_legs','FigureWheels','Head']\n",
    "\n",
    "results = model.predict(X_tests)\n",
    "errors = list()\n",
    "for idx in range(len(results)):\n",
    "    res = results[idx]\n",
    "    cla_pre = clazzez[np.argmax(res)]\n",
    "    cla_tar = clazzez[np.argmax(Y_tests[idx])]\n",
    "    if cla_pre!=cla_tar:\n",
    "#         print(cla_pre,cla_tar)\n",
    "        errors.append(idx)\n",
    "# print(errors)\n",
    "\n",
    "problems = 4\n",
    "fig, axes = plt.subplots(problems, figsize=(10,10))\n",
    "fig.tight_layout()\n",
    "for idx in range(problems):\n",
    "    err = errors[idx]\n",
    "    cla_pre = clazzez[np.argmax(results[err])]\n",
    "    cla_tar = clazzez[np.argmax(Y_tests[err])]    \n",
    "    \n",
    "    axes[idx].imshow(X_tests[err],cmap='gray')\n",
    "    axes[idx].set_title(\"cla_pre=%s cla_tar=%s \" % (cla_pre,cla_tar), fontsize=10)\n",
    "    axes[idx].set_xticks([]) \n",
    "    axes[idx].set_yticks([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
